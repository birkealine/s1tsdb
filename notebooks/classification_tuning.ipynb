{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "\n",
    "from src.constants import AOIS_TEST\n",
    "from src.data import UNOSAT_S1TS_Dataset\n",
    "from src.classification.model_factory import load_model\n",
    "from src.classification.trainer import S1TSDD_Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df, start, end, prefix=\"\"):\n",
    "\n",
    "    # columns are datetime -> can slice directly between two dates\n",
    "    df = df.loc[:, start:end]\n",
    "\n",
    "    # features\n",
    "    df_features = pd.DataFrame(index=df.index)\n",
    "    df_features[\"mean\"] = df.mean(axis=1)\n",
    "    df_features[\"std\"] = df.std(axis=1)\n",
    "    df_features[\"median\"] = df.median(axis=1)\n",
    "    df_features[\"min\"] = df.min(axis=1)\n",
    "    df_features[\"max\"] = df.max(axis=1)\n",
    "    df_features[\"skew\"] = df.skew(axis=1)\n",
    "    df_features[\"kurt\"] = df.kurt(axis=1)\n",
    "\n",
    "    # rename columns using band, prefix (eg pre/post/pre_3x3, ...)\n",
    "    df_vv = df_features.xs(\"VV\", level=\"band\")\n",
    "    df_vh = df_features.xs(\"VH\", level=\"band\")\n",
    "    df_vv.columns = [f\"VV_{prefix}_{col}\" for col in df_vv.columns]\n",
    "    df_vh.columns = [f\"VH_{prefix}_{col}\" for col in df_vh.columns]\n",
    "    return pd.concat([df_vv, df_vh], axis=1)\n",
    "\n",
    "\n",
    "cfg = OmegaConf.create(\n",
    "    dict(\n",
    "        aggregation_method=\"mean\",\n",
    "        model_name=\"random_forest\",\n",
    "        model_kwargs=dict(\n",
    "            n_estimators=100,\n",
    "            n_jobs=12,\n",
    "        ),\n",
    "        data=dict(\n",
    "            aois_test=[f\"UKR{i}\" for i in range(1, 19) if i not in [1, 2, 3, 4]],  # [\"UKR6\", \"UKR8\", \"UKR12\", \"UKR15\"],\n",
    "            damages_to_keep=[1, 2, 3],\n",
    "            extract_winds=[\"3x3\"],  # ['1x1', '3x3', '5x5']\n",
    "            random_neg_labels=0.0,  # percentage of negative labels to add in training set (eg 0.1 for 10%)\n",
    "            time_periods=[\n",
    "                dict(pre=(\"2021-02-24\", \"2022-02-23\"), post=(\"2022-02-24\", \"2023-02-23\")), # negative samples\n",
    "                dict(pre=(\"2020-02-24\", \"2021-02-23\"), post=(\"2021-02-24\", \"2022-02-23\")) # positive samples\n",
    "            ],\n",
    "        ),\n",
    "        seed=123,\n",
    "        run_name=None,\n",
    "    )\n",
    ")\n",
    "\n",
    "ds = UNOSAT_S1TS_Dataset(cfg.data, extract_features=extract_features)\n",
    "df, df_test = ds.get_datasets(\"test\")\n",
    "X = df[[c for c in df.columns if c.startswith((\"VV\", \"VH\"))]].values\n",
    "y = df[\"label\"].values\n",
    "X_test = df_test[[c for c in df_test.columns if c.startswith((\"VV\", \"VH\"))]].values\n",
    "y_test = df_test[\"label\"].values\n",
    "X.shape, y.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = ParameterGrid(\n",
    "    {\n",
    "        \"n_estimators\": [10, 20, 50, 100, 200],\n",
    "        \"max_depth\": [20, 40, None],\n",
    "        # \"min_samples_split\": [2, 4, 8, 16],\n",
    "        \"min_samples_leaf\": [1, 2, 4, 8],\n",
    "        \"max_samples\": [0.5, 1.0],\n",
    "    }\n",
    ")\n",
    "len(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "from src.classification.utils import aggregate_predictions\n",
    "from tqdm import tqdm\n",
    "\n",
    "col_to_keep = [\"aoi\", \"unosat_id\", \"orbit\", \"label\"]\n",
    "d_results = []\n",
    "for param in tqdm(param_grid):\n",
    "\n",
    "    df_preds = df_test[col_to_keep].copy()\n",
    "\n",
    "    clf = RandomForestClassifier(**param, n_jobs=12, random_state=123)\n",
    "    clf.fit(X, y)\n",
    "    df_preds[\"preds_proba\"] = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # aggregate predictions\n",
    "    df_agg = df_preds.groupby([\"aoi\", \"unosat_id\", \"label\"]).agg({\"preds_proba\": \"mean\"}).reset_index()\n",
    "    y_true = df_agg.reset_index()[\"label\"]\n",
    "\n",
    "    # compute metrics for different thresholds\n",
    "    for thresh in [0.5, 0.6, 0.75]:\n",
    "        y_pred_agg_thresh = (df_agg[\"preds_proba\"] > thresh).astype(int)\n",
    "        param[f\"acc_{thresh:.2f}\"] = accuracy_score(y_true, y_pred_agg_thresh)\n",
    "        param[f'precision_{thresh:.2f}'] = precision_score(y_true, y_pred_agg_thresh)\n",
    "        param[f'recall_{thresh:.2f}'] = recall_score(y_true, y_pred_agg_thresh)\n",
    "        param[f'f1_{thresh:.2f}'] = f1_score(y_true, y_pred_agg_thresh)\n",
    "    d_results.append(param)\n",
    "\n",
    "df_results = pd.DataFrame(d_results)\n",
    "df_results.to_csv(\"results_rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.constants import PROJECT_PATH\n",
    "df_results_cv = pd.read_csv(PROJECT_PATH / \"results_rf_cv_all_data.csv\")\n",
    "#df_results_cv = df_results_cv[df_results_cv[\"n_estimators\"] == 100]\n",
    "cols = ['max_depth', 'max_samples', 'min_samples_leaf','n_estimators']\n",
    "cols += [f'f1_{thresh:.2f}' for thresh in [0.5, 0.6, 0.75]]\n",
    "cols += [f'f1_{thresh:.2f}_std' for thresh in [0.5, 0.6, 0.75]]\n",
    "cols += [f'f0.5_{thresh:.2f}' for thresh in [0.5, 0.6, 0.75]]\n",
    "cols += [f'f0.5_{thresh:.2f}_std' for thresh in [0.5, 0.6, 0.75]]\n",
    "df_results_cv.sort_values(\"f0.5_0.50\", ascending=False)[cols].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_cv = pd.read_csv(PROJECT_PATH / \"results_rf_cv_all_data_ntrees.csv\")\n",
    "#df_results_cv = df_results_cv[df_results_cv[\"n_estimators\"] == 100]\n",
    "cols = ['n_estimators']\n",
    "cols += [f'f1_{thresh:.2f}' for thresh in [0.5, 0.6, 0.75]]\n",
    "cols += [f'f1_{thresh:.2f}_std' for thresh in [0.5, 0.6, 0.75]]\n",
    "cols += [f'f0.5_{thresh:.2f}' for thresh in [0.5, 0.6, 0.75]]\n",
    "cols += [f'f0.5_{thresh:.2f}_std' for thresh in [0.5, 0.6, 0.75]]\n",
    "df_results_cv.sort_values(\"f0.5_0.50\", ascending=False)[cols].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
