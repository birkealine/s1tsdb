{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-months postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get files ready for Torben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import PREDS_PATH\n",
    "from src.utils.geometry import load_ukraine_admin_polygons\n",
    "\n",
    "adm1 = load_ukraine_admin_polygons(adm_level=1).set_index('admin_id')\n",
    "adm2 = load_ukraine_admin_polygons(adm_level=2).set_index('admin_id')\n",
    "adm3 = load_ukraine_admin_polygons(adm_level=3).set_index('admin_id')\n",
    "adm4 = load_ukraine_admin_polygons(adm_level=4).set_index('admin_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm1.shape, adm2.shape, adm3.shape, adm4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.geometry import get_best_utm_crs\n",
    "import geopandas as gpd\n",
    "\n",
    "def prepare_gdf_preds(gdf, adm3_id):\n",
    "\n",
    "    gdf_pivot = gdf.reset_index().pivot_table(\n",
    "        index='building_id',\n",
    "        columns='post_date',\n",
    "        values='weighted_mean'\n",
    "    )\n",
    "    gdf = gpd.GeoDataFrame(gdf_pivot.join(gdf.groupby('building_id').agg({'geometry': 'first', 'dataset': 'first'})), crs=gdf.crs)\n",
    "    gdf['area'] = gdf.to_crs(get_best_utm_crs(gdf)).area\n",
    "\n",
    "    # Add admin names and ids\n",
    "    d_admins = {k:v for k,v in adm3.loc[adm3_id].to_dict().items() if k.startswith('ADM')}\n",
    "    for k, v in d_admins.items():\n",
    "        gdf[k] = v\n",
    "\n",
    "    adm1_id = adm1[adm1['ADM1_EN'] == d_admins['ADM1_EN']].index[0]\n",
    "    adm2_id = adm2[(adm2['ADM1_EN'] == d_admins['ADM1_EN']) & (adm2['ADM2_EN'] == d_admins['ADM2_EN'])].index[0]\n",
    "    gdf['adm1_id'] = adm1_id\n",
    "    gdf['adm2_id'] = adm2_id\n",
    "    gdf['adm3_id'] = adm3_id\n",
    "\n",
    "    # For adm4, we need to cross reference with the building polygons\n",
    "    adm4_ = adm4[\n",
    "        (adm4.ADM1_EN == d_admins['ADM1_EN']) &\n",
    "        (adm4.ADM2_EN == d_admins['ADM2_EN']) &\n",
    "        (adm4.ADM3_EN == d_admins['ADM3_EN'])\n",
    "    ]\n",
    "    gdf['ADM4_EN'] = None\n",
    "    gdf['adm4_id'] = None\n",
    "    for adm4_id, adm4_row in adm4_.iterrows():\n",
    "        gdf_ = gdf[gdf.within(adm4_row.geometry)]\n",
    "        gdf.loc[gdf_.index, 'ADM4_EN'] = adm4_row.ADM4_EN\n",
    "        gdf.loc[gdf_.index, 'adm4_id'] = adm4_id\n",
    "\n",
    "    # geomtry as wkt\n",
    "    gdf['geometry_wkt'] = gdf['geometry'].apply(lambda x: x.wkt)\n",
    "\n",
    "    # reset index\n",
    "    gdf = gdf.reset_index()\n",
    "    return gdf[sorted(gdf.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import duckdb\n",
    "from tqdm import tqdm\n",
    "\n",
    "run_name = '240307'\n",
    "\n",
    "db_name = PREDS_PATH / run_name / 'buildings_preds.db'\n",
    "\n",
    "db = duckdb.connect(f'{db_name}')\n",
    "db.execute(\"INSTALL spatial; INSTALL httpfs; LOAD spatial; LOAD httpfs; SET s3_region='us-west-2';\")\n",
    "\n",
    "# Path to the output Parquet file\n",
    "output_parquet_file = './test.parquet'\n",
    "\n",
    "# All geojson files to ingest\n",
    "\n",
    "admin_preds_folder = PREDS_PATH / run_name / 'admin_preds'\n",
    "fps = sorted(admin_preds_folder.glob('*.geojson'))\n",
    "\n",
    "# check if table buildings_preds exists\n",
    "try:\n",
    "    db.execute(\"SELECT COUNT(*) FROM buildings_preds\").fetchall()\n",
    "    table_exists = True\n",
    "\n",
    "    # filter out existing adm3_ids\n",
    "    existing_adm3_ids = db.execute(\"SELECT DISTINCT adm3_id FROM buildings_preds\").fetchdf().adm3_id.values\n",
    "    fps = [fp for fp in fps if fp.stem not in existing_adm3_ids]\n",
    "    print(f'Found {len(existing_adm3_ids)} existing adm3_ids. {len(fps)} new files to process.')\n",
    "except:\n",
    "    table_exists = False\n",
    "    print(f'{len(fps)} files to process.')\n",
    "\n",
    "for fp in tqdm(fps[:3], total=3):\n",
    "\n",
    "    print(fp.stem)\n",
    "\n",
    "    gdf = prepare_gdf_preds(gpd.read_file(fp).set_index(['building_id', 'post_date']), fp.stem)\n",
    "    df = gdf.drop(columns=['geometry'])\n",
    "    df.fillna(999, inplace=True)\n",
    "    # print(f'Dataframe for admin {fp.stem} ready ({df.shape}). Writing to DuckDB...')\n",
    "\n",
    "    # Register the pandas DataFrame with DuckDB\n",
    "    #db.register('df', df)\n",
    "\n",
    "    if not table_exists:\n",
    "        db.execute(\"CREATE TABLE buildings_preds AS SELECT * FROM df\")\n",
    "        table_exists = True\n",
    "    else:\n",
    "        db.execute('INSERT INTO buildings_preds SELECT * FROM df')\n",
    "\n",
    "    # Unregister the DataFrame to avoid conflicts on the next iteration\n",
    "    #db.unregister('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique adm3_id within building_preds\n",
    "unique_adm3_ids = db.execute(\"SELECT DISTINCT adm3_id FROM buildings_preds\").fetchdf().adm3_id.values\n",
    "unique_adm3_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import duckdb\n",
    "from threading import Thread, current_thread\n",
    "from src.utils.time import timeit\n",
    "\n",
    "run_name = '240307'\n",
    "\n",
    "db_name = PREDS_PATH / run_name / 'buildings_preds.db'\n",
    "\n",
    "db = duckdb.connect(f'{db_name}')\n",
    "existing_adm3_ids = db.execute(\"SELECT DISTINCT adm3_id FROM buildings_preds\").fetchdf().adm3_id.values\n",
    "\n",
    "admin_preds_folder = PREDS_PATH / run_name / 'admin_preds'\n",
    "fps = sorted(admin_preds_folder.glob('*.geojson'))\n",
    "fps = [fp for fp in fps if fp.stem not in existing_adm3_ids]\n",
    "\n",
    "@timeit\n",
    "def write_from_thread(adm3_id, db):\n",
    "\n",
    "    # Create a DuckDB connection specifically for this thread\n",
    "    local_db = db.cursor()\n",
    "\n",
    "    # insert into db\n",
    "    fp = admin_preds_folder / f'{adm3_id}.geojson'\n",
    "    gdf = prepare_gdf_preds(gpd.read_file(fp).set_index(['building_id', 'post_date']), fp.stem)\n",
    "    df = gdf.drop(columns=['geometry'])\n",
    "    df.fillna(999, inplace=True)\n",
    "    local_db.execute('INSERT INTO buildings_preds SELECT * FROM df')\n",
    "\n",
    "write_thread_count = 20\n",
    "threads = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(write_thread_count):\n",
    "    print(f'Starting thread {i}. {fps[i].stem}')\n",
    "    threads.append(Thread(target=write_from_thread, args=(fps[i].stem, db)))\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_adm3_ids = db.execute(\"SELECT DISTINCT adm3_id FROM buildings_preds\").fetchdf().adm3_id.values\n",
    "existing_adm3_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps_to_compute = fps[:20]\n",
    "fps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [(i, i+50) for i in range(0, 1000, 50)]\n",
    "\n",
    "n_buildings_area = []\n",
    "for bin in bins:\n",
    "    condition = f\"area > {bin[0]} AND area <= {bin[1]}\" if bin[1] != 2500 else f\"area > {bin[0]}\"\n",
    "    n_buildings_area.append(db.execute(\n",
    "        f\"\"\"\n",
    "            SELECT\n",
    "                COUNT(*)\n",
    "            FROM\n",
    "                buildings_preds\n",
    "            WHERE\n",
    "                {condition}\n",
    "        \"\"\"\n",
    "    ).fetchone()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the histogram of building areas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(range(len(bins)), n_buildings_area)\n",
    "ax.set_xticks(range(len(bins)))\n",
    "ax.set_xticklabels([f'{bin[0]}-{bin[1]}' for bin in bins], rotation=90)\n",
    "ax.set_ylabel('Number of buildings')\n",
    "ax.set_xlabel('Area (m2)')\n",
    "ax.set_title(f'Histogram of building areas (N={sum(n_buildings_area):.2e})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add UNOSAT damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Slow but ok, do it once TODO: DO LIKE WITH CLASS (SEE BELOW)\n",
    "import duckdb\n",
    "from src.data import get_all_aois\n",
    "from src.data.buildings.overture_unosat import load_overture_buildings_aoi\n",
    "from src.utils.time import timeit\n",
    "\n",
    "@timeit\n",
    "def add_unosat_damage_to_db():\n",
    "\n",
    "    run_name = '240307'\n",
    "    db_name = PREDS_PATH / run_name / 'buildings_preds.db'\n",
    "\n",
    "    db = duckdb.connect(f'{db_name}')\n",
    "\n",
    "    # add a column unosat_damage to the table, filled with NULL\n",
    "    try:\n",
    "        db.execute(\"ALTER TABLE buildings_preds ADD COLUMN unosat_damage INT\")\n",
    "    except Exception:\n",
    "        print('Column already exists')\n",
    "\n",
    "\n",
    "    # Fill for all AOIs\n",
    "    for aoi in get_all_aois():\n",
    "\n",
    "        print(f'Processing {aoi}...')\n",
    "\n",
    "        gdf_unosat = load_overture_buildings_aoi(aoi) # contains damage_5m per overture building\n",
    "        gdf_unosat = gdf_unosat[gdf_unosat.damage_5m != 6]\n",
    "\n",
    "        print(f'{len(gdf_unosat)} buildings to update.')\n",
    "\n",
    "        # iterate through UNOSAT damage, could be definitely optimized\n",
    "        for damage_5m, row in gdf_unosat.set_index('damage_5m').iterrows():\n",
    "\n",
    "            # building_id do not match, so we use geometry_wkt instead\n",
    "            db.execute(\n",
    "                f\"\"\"\n",
    "                UPDATE buildings_preds\n",
    "                SET unosat_damage = {damage_5m}\n",
    "                WHERE\n",
    "                    geometry_wkt == '{row.geometry.wkt}'\n",
    "                \"\"\"\n",
    "            )\n",
    "\n",
    "        print(f'Updated {len(gdf_unosat)} buildings.')\n",
    "\n",
    "# add_unosat_damage_to_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import PREDS_PATH\n",
    "import duckdb\n",
    "\n",
    "from src.constants import OVERTURE_BUILDINGS_RAW_PATH\n",
    "\n",
    "FP_RAW_PARQUET = OVERTURE_BUILDINGS_RAW_PATH / \"ukraine_buildings.parquet\"\n",
    "\n",
    "def add_class_to_db():\n",
    "\n",
    "    run_name = '240307'\n",
    "    db_name = PREDS_PATH / run_name / 'buildings_preds.db'\n",
    "\n",
    "    db = duckdb.connect(f'{db_name}')\n",
    "    db.execute(\"INSTALL spatial; INSTALL httpfs; LOAD spatial; LOAD httpfs; SET s3_region='us-west-2';\");\n",
    "\n",
    "    try:\n",
    "        db.execute('ALTER TABLE buildings_preds ADD COLUMN class STRING')\n",
    "    except Exception:\n",
    "        print('already added column class')\n",
    "\n",
    "    # Load the parquet file into the database as a view\n",
    "    db.execute(\n",
    "        f\"\"\"\n",
    "        CREATE OR REPLACE VIEW all_buildings AS\n",
    "        SELECT ST_AsText(ST_GeomFromWKB(geometry)) as geometry_wkt, class\n",
    "        FROM read_parquet('{FP_RAW_PARQUET}', hive_partitioning=1)\n",
    "        WHERE class not NULL\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # perform join operation\n",
    "    db.execute(\n",
    "        f\"\"\"\n",
    "        UPDATE buildings_preds\n",
    "        SET class = all_buildings.class\n",
    "        FROM all_buildings\n",
    "        WHERE buildings_preds.geometry_wkt = all_buildings.geometry_wkt\n",
    "        \"\"\"\n",
    "    )\n",
    "    print('added class to db')\n",
    "\n",
    "add_class_to_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add date unosat damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import load_unosat_labels\n",
    "\n",
    "load_overture_buildings_aoi(aoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import PREDS_PATH\n",
    "import duckdb\n",
    "\n",
    "from src.constants import OVERTURE_BUILDINGS_RAW_PATH\n",
    "\n",
    "\n",
    "FP_RAW_PARQUET = OVERTURE_BUILDINGS_RAW_PATH / \"ukraine_buildings.parquet\"\n",
    "\n",
    "\n",
    "def add_date_unosat_to_db():\n",
    "\n",
    "    run_name = \"240307\"\n",
    "    db_name = PREDS_PATH / run_name / \"buildings_preds.db\"\n",
    "\n",
    "    db = duckdb.connect(f\"{db_name}\")\n",
    "    db.execute(\"INSTALL spatial; INSTALL httpfs; LOAD spatial; LOAD httpfs; SET s3_region='us-west-2';\")\n",
    "\n",
    "    try:\n",
    "        db.execute(\"ALTER TABLE unosat_date_analysis ADD COLUMN class STRING\")\n",
    "    except Exception:\n",
    "        print(\"already added column unosat_date_analysis\")\n",
    "\n",
    "    # Load the parquet file into the database as a view\n",
    "    db.execute(\n",
    "        f\"\"\"\n",
    "        CREATE OR REPLACE VIEW all_labels AS\n",
    "        SELECT date, unosat_id\n",
    "        FROM read_parquet('{FP_RAW_PARQUET}', hive_partitioning=1)\n",
    "        WHERE class not NULL\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # perform join operation\n",
    "    db.execute(\n",
    "        f\"\"\"\n",
    "        UPDATE buildings_preds\n",
    "        SET class = all_buildings.class\n",
    "        FROM all_buildings\n",
    "        WHERE buildings_preds.geometry_wkt = all_buildings.geometry_wkt\n",
    "        \"\"\"\n",
    "    )\n",
    "    print(\"added class to db\")\n",
    "\n",
    "\n",
    "# add_class_to_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from src.constants import PREDS_PATH\n",
    "import geopandas as gpd\n",
    "\n",
    "run_name = '240307'\n",
    "db_name = PREDS_PATH / run_name / 'buildings_preds.db'\n",
    "\n",
    "db = duckdb.connect(f'{db_name}')\n",
    "db.execute(\"INSTALL spatial; INSTALL httpfs; LOAD spatial; LOAD httpfs; SET s3_region='us-west-2';\")\n",
    "filepath = PREDS_PATH / run_name / 'buildings_preds.parquet'\n",
    "db.execute(\n",
    "    f\"\"\"\n",
    "    COPY (\n",
    "        SELECT * FROM buildings_preds\n",
    "    ) TO '{filepath}' WITH (FORMAT 'Parquet');\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Damage but area filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.geometry import load_ukraine_admin_polygons\n",
    "adm3 = load_ukraine_admin_polygons(adm_level=3).set_index('admin_id')\n",
    "adm3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from src.constants import PREDS_PATH\n",
    "import geopandas as gpd\n",
    "\n",
    "run_name = '240307'\n",
    "db_name = PREDS_PATH / run_name / 'buildings_preds.db'\n",
    "\n",
    "db = duckdb.connect(f'{db_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_dates_neg = ['2021-02-24', '2021-05-24', '2021-08-24', '2021-11-24']\n",
    "post_dates = ['2022-02-24', '2022-05-24', '2022-08-24', '2022-11-24', '2023-02-24', '2023-05-24', '2023-08-24', '2023-11-24']\n",
    "condition = ' OR '.join([f'\"{post_date}\" >= 255*0.65' for post_date in post_dates])\n",
    "conditon_neg = ' AND '.join([f'\"{post_date}\" < 255*0.65' for post_date in post_dates_neg])\n",
    "condition = f'({condition}) AND ({conditon_neg})'\n",
    "\n",
    "df = db.execute(\n",
    "    f\"\"\"\n",
    "        SELECT adm3_id, ADM3_EN, COUNT(*) as count\n",
    "        FROM buildings_preds\n",
    "        WHERE {condition}\n",
    "        GROUP BY adm3_id, ADM3_EN\n",
    "        ORDER BY count DESC\n",
    "    \"\"\"\n",
    ").fetchdf().set_index('adm3_id')\n",
    "gdf = gpd.GeoDataFrame(df.join(adm3[['geometry']], how='left'), crs=adm3.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "area_lims = np.concatenate([np.arange(0,100,10), np.arange(100, 1500, 50), [1500, 2000,2500]])\n",
    "n_tot_buildings = []\n",
    "for area_lim in area_lims:\n",
    "    n_tot_buildings.append(db.execute(\n",
    "        f\"\"\"\n",
    "            SELECT COUNT(*)\n",
    "            FROM buildings_preds\n",
    "            WHERE {condition} AND area > {area_lim}\n",
    "        \"\"\"\n",
    "    ).fetchall()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "ax.bar(range(len(area_lims)), n_tot_buildings)\n",
    "ax.semilogy()\n",
    "ax.set_xticks(range(len(area_lims)))\n",
    "ax.set_xticklabels([f'{area_lim}' for area_lim in area_lims], rotation=90)\n",
    "ax.set_ylabel('Number of buildings')\n",
    "ax.set_xlabel('Minimum Area (m2)')\n",
    "ax.set_title(f'Building destroyed vs minimum area (N={sum(n_tot_buildings):.2e})')\n",
    "for i, v in enumerate(n_tot_buildings):\n",
    "    ax.text(i, v, f'{v:.2e}', ha='center', va='bottom', fontsize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(\n",
    "    f\"\"\"\n",
    "        SELECT COUNT(*), dataset\n",
    "        FROM buildings_preds\n",
    "        WHERE area > 50\n",
    "        GROUP BY dataset\n",
    "    \"\"\"\n",
    ").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (31+13/60)/6.09\n",
    "print(f'{np.floor(t)} min and {np.ceil((t-np.floor(t))*60)} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (30+16/60)/6.38\n",
    "print(f'{np.floor(t)} min and {np.ceil((t-np.floor(t))*60)} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
