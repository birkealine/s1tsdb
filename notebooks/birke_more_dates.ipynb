{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOs left\n",
    "- [ ] create different configs for the different cases \n",
    "- [ ] incorporate PyDrive again \n",
    "- [ ] stitch quadkeys back together / link them with UNOSAT labels in order to evaluate them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create config with all the stuff necessary below\n",
    "from omegaconf import DictConfig, OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ukraine: \n",
    "cfg_ukr = OmegaConf.create(\n",
    "        dict(\n",
    "        #     aggregation_method=\"mean\",\n",
    "        #     model_name=\"random_forest\",\n",
    "        #     model_kwargs=dict(\n",
    "        #         numberOfTrees=100,\n",
    "        #         minLeafPopulation=3,\n",
    "        #         maxNodes=1e4,\n",
    "        #     ),\n",
    "            data=dict(\n",
    "                # aois_test=[f\"UKR{i}\" for i in range(1, 19) if i not in [1, 2, 3, 4]],\n",
    "                # damages_to_keep=[1, 2],\n",
    "                extract_winds=[\"3x3\"]#,  # ['1x1', '3x3', '5x5']\n",
    "                # time_periods={  # to train\n",
    "                #     \"pre\": (\"2020-02-24\", \"2021-02-23\"),  # always only one\n",
    "                #     \"post\": \"3months\",\n",
    "                # },\n",
    "            ),\n",
    "            inference=dict(\n",
    "                country=\"Ukraine\", #added country identifier\n",
    "                time_periods={\n",
    "                    \"pre\": (\"2020-02-24\", \"2021-02-23\"),  # always only one\n",
    "                    \"post\": [\n",
    "                        (\"2021-02-24\", \"2021-05-23\"),\n",
    "                        (\"2021-05-24\", \"2021-08-23\"),\n",
    "                        (\"2021-08-24\", \"2021-11-23\"),\n",
    "                        (\"2021-11-24\", \"2022-02-23\"),\n",
    "                        (\"2022-02-24\", \"2022-05-23\"), # actual start of invasion: 24.02.2022\n",
    "                        (\"2022-05-24\", \"2022-08-23\"),\n",
    "                        (\"2022-08-24\", \"2022-11-23\"),\n",
    "                        (\"2022-11-24\", \"2023-02-23\")\n",
    "                    ],\n",
    "                },\n",
    "                quadkey_zoom=8,\n",
    "            ),\n",
    "            reducer_names=[\"mean\", \"stdDev\", \"median\", \"min\", \"max\", \"skew\", \"kurtosis\"],\n",
    "            # train_on_all=False,  # train on all damages (train + test split)\n",
    "            verbose=0,\n",
    "            # export_as_trees=False, \n",
    "            # seed=123,\n",
    "            run_name=\"240307\",  # must be string\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syria: \n",
    "cfg_syria = OmegaConf.create(\n",
    "        dict(\n",
    "        #     aggregation_method=\"mean\",\n",
    "        #     model_name=\"random_forest\",\n",
    "        #     model_kwargs=dict(\n",
    "        #         numberOfTrees=100,\n",
    "        #         minLeafPopulation=3,\n",
    "        #         maxNodes=1e4,\n",
    "        #     ),\n",
    "            data=dict(\n",
    "                # aois_test=[f\"UKR{i}\" for i in range(1, 19) if i not in [1, 2, 3, 4]],\n",
    "                # damages_to_keep=[1, 2],\n",
    "                extract_winds=[\"3x3\"]#,  # ['1x1', '3x3', '5x5']\n",
    "                # time_periods={  # to train\n",
    "                #     \"pre\": (\"2020-02-24\", \"2021-02-23\"),  # always only one\n",
    "                #     \"post\": \"3months\",\n",
    "                # },\n",
    "            ),\n",
    "            inference=dict(\n",
    "                country=\"Syria\", #added country identifier\n",
    "                time_periods={ # should be oriented at UNOSAT before and afters if possible\n",
    "                    \"pre\": (\"2020-02-24\", \"2021-02-23\"),  # always only one\n",
    "                    \"post\": [\n",
    "                        (\"2021-02-24\", \"2021-05-23\"),\n",
    "                        (\"2021-05-24\", \"2021-08-23\")#,\n",
    "                        #(\"2021-08-24\", \"2021-11-23\"),\n",
    "                        #(\"2021-11-24\", \"2022-02-23\"),\n",
    "                        #(\"2022-02-24\", \"2022-05-23\"),\n",
    "                        #(\"2022-05-24\", \"2022-08-23\"),\n",
    "                        #(\"2022-08-24\", \"2022-11-23\"),\n",
    "                        #(\"2022-11-24\", \"2023-02-23\"),\n",
    "                    ],\n",
    "                },\n",
    "                quadkey_zoom=8,\n",
    "            ),\n",
    "            reducer_names=[\"mean\", \"stdDev\", \"median\", \"min\", \"max\", \"skew\", \"kurtosis\"],\n",
    "            # train_on_all=False,  # train on all damages (train + test split)\n",
    "            verbose=0,\n",
    "            # export_as_trees=False, \n",
    "            # seed=123,\n",
    "            run_name=\"240307\",  # must be string\n",
    "        )\n",
    "    )\n",
    "\n",
    "#TODO adapt for other countries: create different configs for the different cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. load trained model from GEE assets\n",
    "from src.gee.classification.model import load_classifier\n",
    "asset_id = \"projects/rmac-ethz/assets/s1tsdd_Ukraine/240307/classifier_3months_100trees\"\n",
    "classifier = load_classifier(asset_id) #load trained classifier (by olivier) from GEE assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. ####### NEW - PREDICT AND EXPORT FUNCTION TO WORK FOR OTHER REGIONS FLEXIBLY ######\n",
    "\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for creating the quadkey grid\n",
    "from src.data.quadkeys import load_country_quadkeys_grid\n",
    "from shapely.geometry import mapping\n",
    "import ee\n",
    "from src.utils.gee import init_gee\n",
    "init_gee()\n",
    "\n",
    "# from src.gee.constants import ASSETS_PATH\n",
    "from src.gee.classification.inference import predict_geo\n",
    "# from src.utils.gdrive import get_files_in_folder #TODO had to remove this bc linked to pydrive\n",
    "\n",
    "def predict_and_export_all_grids(\n",
    "    classifier: ee.Classifier,\n",
    "    cfg: DictConfig,\n",
    "    folder: str,\n",
    "    # ids: List[str] = None,\n",
    "    # n_limit: int = None,\n",
    "    verbose: int = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Predict and export for all grids (quadkeys) in Ukraine.\n",
    "\n",
    "    If ids is not None, predict only these grids. If n_limit is given, only predict on n_limit grids.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get all grids\n",
    "    print(f\"Predicting for quadkey grid for {cfg.inference.country} with zoom {cfg.inference.quadkey_zoom}\")\n",
    "    # grids = ee.FeatureCollection(ASSETS_PATH + f\"s1tsdd_Ukraine/quadkeys_grid_zoom{cfg.inference.quadkey_zoom}\") \n",
    "    # instead: create quadkey COUNTRY grid: \n",
    "    grids = load_country_quadkeys_grid(zoom=cfg.inference.quadkey_zoom, country=cfg.inference.country) # if there isn't a quadkey grid yet: one will be created\n",
    "    grids[\"geomee\"] = grids.apply(lambda x: ee.Geometry(mapping(x['geometry'])), axis = 1) # add column with ee.Geometries() which is necessary for applying the model\n",
    "\n",
    "    # if ids is None:\n",
    "    #     # No IDs were given, we predict on all (or n_limit if given)\n",
    "    #     if n_limit:\n",
    "    #         # For debugging\n",
    "    #         grids = grids.limit(n_limit)\n",
    "    #     ids = grids.aggregate_array(\"qk\").getInfo()\n",
    "    # else:\n",
    "    #     # make sure ids are strings\n",
    "    #     ids = [str(id_) for id_ in ids]\n",
    "\n",
    "    # Filter IDs that have already been predicted (names are qk_12345678.tif for instance) #TODO removed bc reliant on pydrive which doesnt work atm\n",
    "    # files = get_files_in_folder(folder, return_names=True)\n",
    "    # existing_names = [f.split(\".\")[0] for f in files if f.startswith(\"qk_\")]\n",
    "    # ids = [id_ for id_ in ids if id_ not in existing_names]\n",
    "\n",
    "    # get operations still running\n",
    "    def get_description(id_):\n",
    "        return f\"{cfg.run_name}_qk{id_}_{'_'.join(cfg.inference.time_periods.post)}\"\n",
    "\n",
    "    # ops = [o for o in ee.data.listOperations() if o[\"metadata\"][\"state\"] in [\"PENDING\", \"RUNNING\"]]\n",
    "    # ids_running = [o[\"metadata\"][\"description\"] for o in ops]\n",
    "    # ids = [id_ for id_ in ids if get_description(id_) not in ids_running]\n",
    "\n",
    "    print(f\"Predicting and exporting {len(grids)} grids\")\n",
    "    for i in tqdm(range(len(grids))):\n",
    "\n",
    "        grid = grids.iloc[i]\n",
    "        preds = predict_geo(\n",
    "            grid.geomee,\n",
    "            classifier,\n",
    "            cfg.inference.time_periods,\n",
    "            cfg.data.extract_winds,\n",
    "            cfg.reducer_names,\n",
    "            orbits=None,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        preds = preds.set(\"qk\", grid.qk)\n",
    "\n",
    "        name = f\"qk_{grid.qk}\"\n",
    "        task = ee.batch.Export.image.toDrive(\n",
    "            image=preds.multiply(2**8 - 1).toUint8(),  # multiply by 255 and convert to uint8\n",
    "            description=get_description(grid.qk),\n",
    "            folder=folder,\n",
    "            fileNamePrefix=name,\n",
    "            region=grid.geomee,\n",
    "            scale=10,\n",
    "            maxPixels=1e13,\n",
    "        )\n",
    "        task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### OLD / ADAPTED FROM OLIVIER / ONLY WORKS FOR UKRAINE ######\n",
    "\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.gee.constants import ASSETS_PATH\n",
    "from src.gee.classification.inference import predict_geo\n",
    "# from src.utils.gdrive import get_files_in_folder #TODO had to remove this bc linked to pydrive\n",
    "\n",
    "def predict_and_export_all_grids(\n",
    "    classifier: ee.Classifier,\n",
    "    cfg: DictConfig,\n",
    "    folder: str,\n",
    "    ids: List[str] = None,\n",
    "    n_limit: int = None,\n",
    "    verbose: int = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Predict and export for all grids (quadkeys) in Ukraine.\n",
    "\n",
    "    If ids is not None, predict only these grids. If n_limit is given, only predict on n_limit grids.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get all grids\n",
    "    print(f\"Predicting for quadkey grid with zoom {cfg.inference.quadkey_zoom}\")\n",
    "    grids = ee.FeatureCollection(ASSETS_PATH + f\"s1tsdd_Ukraine/quadkeys_grid_zoom{cfg.inference.quadkey_zoom}\") #TODO how to adapt this for other countries? could I also get this from elsewhere? \n",
    "    #TODO turn quadkeys for other regions (clipped to country or AOI borders) into ee.FeatureCollection (check birke_test.ipynb for this)\n",
    "    #OR doesnt necessarily have to work with quadkeys - could also just create ee.FeatureCollection of areas I want to co\n",
    "    # ver (e.g. all AOIs) through which I can loop later\n",
    "\n",
    "    if ids is None:\n",
    "        # No IDs were given, we predict on all (or n_limit if given)\n",
    "        if n_limit:\n",
    "            # For debugging\n",
    "            grids = grids.limit(n_limit)\n",
    "        ids = grids.aggregate_array(\"qk\").getInfo()\n",
    "    else:\n",
    "        # make sure ids are strings\n",
    "        ids = [str(id_) for id_ in ids]\n",
    "\n",
    "    # Filter IDs that have already been predicted (names are qk_12345678.tif for instance) #TODO removed bc reliant on pydrive which doesnt work atm\n",
    "    # files = get_files_in_folder(folder, return_names=True)\n",
    "    # existing_names = [f.split(\".\")[0] for f in files if f.startswith(\"qk_\")]\n",
    "    # ids = [id_ for id_ in ids if id_ not in existing_names]\n",
    "\n",
    "    # get operations still running\n",
    "    def get_description(id_):\n",
    "        return f\"{cfg.run_name}_qk{id_}_{'_'.join(cfg.inference.time_periods.post)}\"\n",
    "\n",
    "    ops = [o for o in ee.data.listOperations() if o[\"metadata\"][\"state\"] in [\"PENDING\", \"RUNNING\"]]\n",
    "    ids_running = [o[\"metadata\"][\"description\"] for o in ops]\n",
    "    ids = [id_ for id_ in ids if get_description(id_) not in ids_running]\n",
    "\n",
    "    print(f\"Predicting and exporting {len(ids)} grids\")\n",
    "    for id_ in tqdm(ids):\n",
    "\n",
    "        grid = grids.filter(ee.Filter.eq(\"qk\", id_))\n",
    "        preds = predict_geo(\n",
    "            grid.geometry(),\n",
    "            classifier,\n",
    "            cfg.inference.time_periods,\n",
    "            cfg.data.extract_winds,\n",
    "            cfg.reducer_names,\n",
    "            orbits=None,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        preds = preds.set(\"qk\", id_)\n",
    "\n",
    "        name = f\"qk_{id_}\"\n",
    "        task = ee.batch.Export.image.toDrive(\n",
    "            image=preds.multiply(2**8 - 1).toUint8(),  # multiply by 255 and convert to uint8\n",
    "            description=get_description(id_),\n",
    "            folder=folder,\n",
    "            fileNamePrefix=name,\n",
    "            region=grid.geometry(),\n",
    "            scale=10,\n",
    "            maxPixels=1e13,\n",
    "        )\n",
    "        task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. apply function to work flexibly with different country configs\n",
    "# TODO incl. creating separate folders etc. for different quadkeys BUT atm cannot download client id - solved this for now by creating folders manually\n",
    "# from src.utils.gdrive import create_drive_folder, create_yaml_file_in_drive_from_config_dict\n",
    "\n",
    "def apply_function(\n",
    "    classifier: ee.Classifier,\n",
    "    cfg: DictConfig\n",
    "):\n",
    "    base_folder_name = f\"{cfg.run_name}_quadkeys_predictions\"\n",
    "\n",
    "    # try:\n",
    "    #     # Create drive folder and save config\n",
    "    #     create_drive_folder(base_folder_name)\n",
    "    #     create_yaml_file_in_drive_from_config_dict(cfg, base_folder_name)\n",
    "    # except Exception:\n",
    "    #     # get input from user to be sure they want to continue\n",
    "    #     print(\"Folder already exists. Continue? (y/n)\")\n",
    "    #     user_input = input()\n",
    "    #     if user_input != \"y\":\n",
    "    #         raise ValueError(\"Interrupted\")\n",
    "\n",
    "    post_periods = cfg.inference.time_periods.post\n",
    "\n",
    "    for post_period in post_periods:\n",
    "\n",
    "        folder_name = f\"{base_folder_name}/{'_'.join(post_period)}\"\n",
    "        cfg.inference.time_periods.post = post_period\n",
    "\n",
    "        # try:\n",
    "        #     # Create drive folder and save config\n",
    "        #     create_drive_folder(folder_name)\n",
    "        # except Exception:\n",
    "        #     # get input from user to be sure they want to continue\n",
    "        #     print(\"Folder already exists. Continue? (y/n)\")\n",
    "        #     user_input = input()\n",
    "        #     if user_input != \"y\":\n",
    "        #         raise ValueError(\"Interrupted\")\n",
    "\n",
    "        \n",
    "        # Launch predictions\n",
    "        predict_and_export_all_grids(\n",
    "            classifier=classifier,\n",
    "            cfg=cfg,\n",
    "            folder=folder_name.split(\"/\")[-1], \n",
    "            ids=None,\n",
    "            n_limit=None,\n",
    "            verbose=cfg.verbose,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. actually run the function now with the specified country-config file\n",
    "apply_function(classifier=classifier, cfg=cfg_syria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: stitch quadkeys back together / link them with UNOSAT labels in order to evaluate them \n",
    "#might make sense to put them into a geodatabase -> have in different tables the links with admin regions, AOIs, and buildings maybe? => ON HOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.postprocessing.utils import read_fp_within_geo \n",
    "from src.constants import PREDS_PATH\n",
    "from src.utils.geometry import load_country_boundaries\n",
    "\n",
    "ukr_geo = load_country_boundaries(\"Ukraine\")\n",
    "fp = PREDS_PATH / cfg.run_name / \"qk_12021333.tif\"\n",
    "preds_arr = read_fp_within_geo(fp, ukr_geo)\n",
    "preds_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_arr.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s1ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
