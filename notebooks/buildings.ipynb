{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft Buildings Footprints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create/Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "location = 'Ukraine'\n",
    "dataset_links = pd.read_csv(\n",
    "    \"https://minedbuildings.blob.core.windows.net/global-buildings/dataset-links.csv\"  # noqa E501\n",
    ")\n",
    "links = dataset_links[dataset_links.Location == location].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string such as 50.9KB to bytes\n",
    "\n",
    "def convert_to_bytes(size):\n",
    "    if size[-2:] == \"KB\":\n",
    "        return int(float(size[:-2]) * 1024)\n",
    "    elif size[-2:] == \"MB\":\n",
    "        return int(float(size[:-2]) * 1024 * 1024)\n",
    "    elif size[-2:] == \"GB\":\n",
    "        return int(float(size[:-2]) * 1024 * 1024 * 1024)\n",
    "    elif size[-1] == 'B':\n",
    "        return int(float(size[:-1]))\n",
    "    else:\n",
    "        return int(size)\n",
    "\n",
    "links['bytes'] = links['Size'].apply(convert_to_bytes)\n",
    "print(f'Total size of the dataset: {links[\"bytes\"].sum() / 1024**3:.2f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.buildings.microsoft import download_microsoft_footprint\n",
    "\n",
    "download_microsoft_footprint(location='Ukraine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Vectorize predictions\n",
    "\n",
    "nb: could also rasterize buildings instead: e.g. https://code.usgs.gov/arc/rasterized-building-footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rxr\n",
    "from src.constants import PROJECT_PATH, PREDS_PATH\n",
    "import rasterio\n",
    "from src.data.buildings.microsoft import quadkeys_in_shape, load_buildings_geo\n",
    "from src.data.unosat import get_unosat_geometry\n",
    "\n",
    "def read_fp_within_geo(fp, geo):\n",
    "\n",
    "    with rasterio.open(fp) as src:\n",
    "        wind = rasterio.windows.from_bounds(*geo.bounds, src.transform)\n",
    "        # data = src.read(window=wind)\n",
    "    xa = rxr.open_rasterio(fp).rio.isel_window(wind)\n",
    "    return xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "geo = box(31.32567,51.50041, 31.38216,51.53648)# zoom top-right UKR6\n",
    "\n",
    "# geo = get_unosat_geometry(aoi)\n",
    "fp = PREDS_PATH / '240212/240212_global_ukraine_preds.tif'\n",
    "assert fp.exists()\n",
    "gdf = load_buildings_geo(geo)\n",
    "xa = read_fp_within_geo(fp, geo).squeeze()\n",
    "gdf.shape, xa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 With rasterstats zonal_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterstats import zonal_stats\n",
    "\n",
    "df_stats = pd.DataFrame(zonal_stats(\n",
    "    vectors=gdf.to_crs(xa.rio.crs),\n",
    "    raster=xa.squeeze().values,\n",
    "    affine=xa.rio.transform(),\n",
    "    stats=['mean', 'std', 'min', 'max'],\n",
    "    nodata=xa.rio.nodata\n",
    "))\n",
    "print(df_stats.shape)\n",
    "df_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 With xagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.constants import PROJECT_PATH\n",
    "\n",
    "# need this before importing xagg\n",
    "os.environ['ESMFMKFILE'] = str(PROJECT_PATH / 's1tsdd-env/lib/esmf.mk')\n",
    "\n",
    "import xagg\n",
    "\n",
    "ds = xa.to_dataset(name='preds')\n",
    "weightmap = xagg.pixel_overlaps(ds, gdf, impl='dot_product', subset_bbox=False)\n",
    "agg_out = xagg.aggregate(ds, weightmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xagg = agg_out.agg\n",
    "df_xagg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Check differences between the two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge gdf with df_xagg on building_id\n",
    "\n",
    "gdf_xagg = gdf.merge(df_xagg, on='building_id')\n",
    "gdf_xagg['preds'] = gdf_xagg.preds.apply(lambda x: float(x[0]))\n",
    "gdf_xagg[['geometry', 'preds']].to_file('test_xagg.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_xagg[['geometry', 'preds']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.index.name='building_id'\n",
    "df_stats.reset_index()\n",
    "gdf_zonal = gdf.merge(df_stats.reset_index(), on='building_id')\n",
    "gdf_zonal.to_file('test_zonal.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['preds'].to_netcdf('test_xa.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_zonal.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_xagg.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Custom method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "import warnings\n",
    "import xarray as xr\n",
    "\n",
    "from src.constants import PROCESSED_PATH\n",
    "\n",
    "def vectorize_xarray(xa: xr.DataArray, gdf: gpd.GeoDataFrame):\n",
    "\n",
    "    if len(xa.shape) != 2:\n",
    "        xa = xa.squeeze()\n",
    "        assert len(xa.shape) == 2, 'xarray should be 2D'\n",
    "\n",
    "    # Construct dataframe with one geometry per pixel\n",
    "    x,y,v = xa.x.values, xa.y.values, xa.values\n",
    "    x,y = np.meshgrid(x,y)\n",
    "    x,y,v = x.flatten(), y.flatten(), v.flatten()\n",
    "    df = pd.DataFrame.from_dict({'x': x, 'y': y, 'v': v})\n",
    "    gdf_pixels = gpd.GeoDataFrame(v, geometry=gpd.GeoSeries.from_xy(df.x, df.y), columns=['preds'], crs=xa.rio.crs)\n",
    "    gdf_pixels.index.name = 'pixel_id'\n",
    "    gdf_pixels.reset_index(inplace=True)\n",
    "\n",
    "    # Buffer the pixels to get one polygon per pixel\n",
    "    res = xa.rio.resolution()\n",
    "    buffer = res[0] / 2 # half the pixel size, assuming square pixels\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore',category=UserWarning)\n",
    "        gdf_pixels['geometry'] = gdf_pixels.buffer(buffer, cap_style=3)\n",
    "    print('Pixels vectorized.')\n",
    "\n",
    "    # Intersect the pixels with the buildings\n",
    "    overlap = gpd.overlay(gdf, gdf_pixels, how='intersection')\n",
    "    print('Pixels intersected with polygons.')\n",
    "\n",
    "    # Calculate the value of the band at each polygon as the weighted area of the intersected pixels\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore',category=UserWarning)\n",
    "        overlap['polygon_area'] = overlap.area\n",
    "    preds_agg = overlap.groupby('building_id').apply(\n",
    "        lambda row: (row['preds'] * row['polygon_area']).sum() / row['polygon_area'].sum()\n",
    "    ).reset_index(name='preds_agg')\n",
    "    print('Prediction aggregated.')\n",
    "\n",
    "    return preds_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = box(31.32567,51.50041, 31.38216,51.53648)# zoom top-right UKR6\n",
    "aoi = 'UKR3'\n",
    "geo = get_unosat_geometry(aoi)\n",
    "fp = PROCESSED_PATH / 'settlements_predictions' / '240212' / '240212_global_ukraine_preds.tif'\n",
    "\n",
    "gdf = get_buildings_geo(geo)\n",
    "preds = read_fp_within_geo(fp, geo).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_agg = vectorize_xarray(preds, gdf)\n",
    "print(preds_agg.shape)\n",
    "preds_agg.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
