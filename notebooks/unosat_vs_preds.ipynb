{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare preds with UNOSAT labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "import warnings\n",
    "\n",
    "\n",
    "from src.data.buildings.overture_unosat import load_overture_buildings_aoi\n",
    "from src.data import get_unosat_geometry\n",
    "from src.data.utils import get_all_aois\n",
    "from src.postprocessing.drive_to_results import find_post_dates\n",
    "from src.postprocessing.utils import read_fp_within_geo, vectorize_xarray_3d\n",
    "from src.constants import PREDS_PATH\n",
    "\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_preds_geo(geo, run_name):\n",
    "\n",
    "    post_dates = find_post_dates(run_name)\n",
    "    post_dates_ = [p[0] for p in post_dates]  # keep only first date for reference\n",
    "\n",
    "    # Read and stack preds for each date\n",
    "    fp_preds = [PREDS_PATH / run_name / f'ukraine_{\"_\".join(post_date)}.tif' for post_date in post_dates]\n",
    "    dates = xr.Variable(\"date\", pd.to_datetime(post_dates_))\n",
    "    preds = xr.concat(\n",
    "        [read_fp_within_geo(fp, geo) for fp in fp_preds], dim=dates\n",
    "    ).squeeze()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aois_train = [f'UKR{i}' for i in range(1,5)]\n",
    "aois_test = [aoi for aoi in get_all_aois() if aoi not in aois_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = '240301'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import load_unosat_labels\n",
    "\n",
    "def extract_raster_value(point, raster):\n",
    "    value = raster.sel(x=point.x, y=point.y, method=\"nearest\").item()\n",
    "    return value\n",
    "\n",
    "def combine_all_unosat_points_with_preds(run_name):\n",
    "    gdf_labels_ = None\n",
    "    for aoi in tqdm(get_all_aois()):\n",
    "        geo = get_unosat_geometry(aoi)\n",
    "        preds = get_preds_geo(geo, run_name)\n",
    "        gdf_labels = load_unosat_labels(aoi, labels_to_keep=[1,2])[['geometry']]\n",
    "        gdf_labels['aoi'] = aoi\n",
    "        for date in ['2021-02-24', '2022-02-24', '2023-02-24']:\n",
    "            gdf_labels[f'pred_{date}'] = gdf_labels.geometry.apply(lambda x: extract_raster_value(x, preds.sel(date=date)))\n",
    "\n",
    "        gdf_labels_ = pd.concat([gdf_labels_, gdf_labels]) if gdf_labels_ is not None else gdf_labels\n",
    "\n",
    "    gdf_labels_.to_file(PREDS_PATH / run_name / 'aoi_preds' / 'unosat_points_with_preds.geojson', driver='GeoJSON')\n",
    "\n",
    "def load_unosat_points_with_preds(run_name):\n",
    "    fp = PREDS_PATH / run_name / 'aoi_preds' / 'unosat_points_with_preds.geojson'\n",
    "    assert fp.exists(), f\"File {fp} does not exist.\"\n",
    "    return gpd.read_file(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine_all_unosat_points_with_preds(run_name)\n",
    "gdf_points = load_unosat_points_with_preds(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for split in ['train', 'test']:\n",
    "\n",
    "    gdf_ = gdf_points[gdf_points.aoi.isin(aois_train if split=='train' else aois_test)]\n",
    "    d[split] = {}\n",
    "    for date in ['2021-02-24', '2022-02-24', '2023-02-24']:\n",
    "        d[split][date] = {}\n",
    "        for t in [0.5, 0.65, 0.75]:\n",
    "            tp = (gdf_[f'pred_{date}']>=255*t).sum()\n",
    "            fn = (gdf_[f'pred_{date}']<255*t).sum()\n",
    "            recall = tp/(tp+fn)\n",
    "            if date == '2021-02-24':\n",
    "                recall = 1-recall\n",
    "            d[split][date][t] = f'{recall:.2f}'\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split = 'test'\n",
    "date_neg = '2021-02-24'\n",
    "date = '2022-02-24'\n",
    "gdf_ = gdf_points[gdf_points.aoi.isin(aois_train if split=='train' else aois_test)]\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "f05s = []\n",
    "f01s = []\n",
    "thresholds = np.arange(0.1,0.9, 0.01)\n",
    "for t in thresholds:\n",
    "    tp = (gdf_[f'pred_{date}']>=255*t).sum()\n",
    "    fn = (gdf_[f'pred_{date}']<255*t).sum()\n",
    "    fp = (gdf_[f'pred_{date_neg}']>=255*t).sum()\n",
    "    tn = (gdf_[f'pred_{date_neg}']<255*t).sum()\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1 = 2*(precision*recall)/(precision+recall)\n",
    "    beta=0.5\n",
    "    f05 = (1+beta**2)*tp/((1+beta**2)*tp+fp + beta**2*fn)\n",
    "    beta=0.1\n",
    "    f01 = (1+beta**2)*tp/((1+beta**2)*tp+fp + beta**2*fn)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "    f05s.append(f05)\n",
    "    f01s.append(f01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(thresholds, precisions, label='Precision')\n",
    "ax.plot(thresholds, recalls, label='Recall')\n",
    "ax.plot(thresholds, f1s, label='F1')\n",
    "ax.plot(thresholds, f05s, label='F0.5')\n",
    "ax.plot(thresholds, f01s, label='F0.1')\n",
    "ax.legend(loc='lower left')\n",
    "ax.vlines(0.5, 0, 1, color='black', linestyle='--')\n",
    "ax.set_xlabel('Threshold')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlim(0.1, 0.9)\n",
    "ax.set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scores, name in zip([f1s, f05s, f01s], ['F1', 'F0.5', 'F0.1']):\n",
    "    print(f\"Best {name} score: {max(scores):.2f} at threshold {thresholds[np.argmax(scores)]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([0] * len(gdf_) + [1] * len(gdf_))\n",
    "y_preds = np.array(gdf_[f'pred_{date_neg}'].tolist() + gdf_[f'pred_{date}'].tolist()) / 255\n",
    "\n",
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "gmeans = np.sqrt(tpr * (1-fpr))\n",
    "ix = np.argmax(gmeans)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot([0,1], [0,1], linestyle='--', color='black')\n",
    "ax.plot(fpr, tpr, label=f'ROC AUC = {roc_auc:.2f}')\n",
    "ax.scatter(fpr[ix], tpr[ix], marker='o', color='black', label=f'Best threshold = {thresholds[ix]:.2f}')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(8,5))\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(y_true, y_preds)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "ix = np.argmax(fscore)\n",
    "ax.plot(recall, precision, label='Precision-Recall')\n",
    "ax.scatter(recall[ix], precision[ix], marker='o', color='black', label=f'Best (threshold={thresholds[ix]:.2f})')\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_preds_to_gdf(gdf, preds, verbose=0):\n",
    "\n",
    "    dates = sorted([d.dt.strftime('%Y-%m-%d').item() for d in preds.date])\n",
    "\n",
    "    # Vectorize pixels\n",
    "    gdf_pixels = vectorize_xarray_3d(preds, dates)\n",
    "    if verbose:\n",
    "        print(f\"Vectorized pixels ({gdf_pixels.shape})\")\n",
    "\n",
    "    # Overlap with buildings\n",
    "    overlap = gpd.overlay(gdf.reset_index(), gdf_pixels, how=\"intersection\").set_index(\"building_id\")\n",
    "    if verbose:\n",
    "        print(f\"Overlap with buildings ({overlap.shape})\")\n",
    "\n",
    "    # Add area of overlap\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "        overlap[\"polygon_area\"] = overlap.area\n",
    "\n",
    "    # Compute weighted mean for each building and date\n",
    "    overlap[[f\"{d}_weighted_value\" for d in dates]] = overlap[dates].multiply(\n",
    "        overlap[\"polygon_area\"], axis=0\n",
    "    )\n",
    "    grps = overlap.groupby(\"building_id\")\n",
    "    gdf_weighted_mean = (\n",
    "        grps[[f\"{d}_weighted_value\" for d in dates]].sum().divide(grps[\"polygon_area\"].sum(), axis=0)\n",
    "    )\n",
    "    gdf_weighted_mean = gdf_weighted_mean.stack().reset_index(level=1)\n",
    "    gdf_weighted_mean.columns = [\"post_date\", \"weighted_mean\"]\n",
    "    gdf_weighted_mean[\"post_date\"] = gdf_weighted_mean[\"post_date\"].apply(lambda x: x.split(\"_\")[0])\n",
    "    gdf_weighted_mean.set_index(\"post_date\", append=True, inplace=True)\n",
    "\n",
    "    # Compute max value for each building and date\n",
    "    gdf_max = overlap.groupby(\"building_id\")[dates].max().stack().to_frame(name=\"max\")\n",
    "    gdf_max.index.names = [\"building_id\", \"post_date\"]\n",
    "\n",
    "    # Merge with original buildings\n",
    "    gdf_with_preds = gdf.join(gdf_weighted_mean).join(gdf_max).sort_index()\n",
    "    return gdf_with_preds\n",
    "\n",
    "def load_aoi_buildings_with_preds(aoi, run_name):\n",
    "    folder = PREDS_PATH / run_name / 'aoi_preds'\n",
    "    fp = folder / f'{aoi}_buildings_with_preds.geojson'\n",
    "    assert fp.exists(), f\"File {fp} does not exist.\"\n",
    "    return gpd.read_file(fp).set_index(['building_id', 'post_date'])\n",
    "\n",
    "def create_aoi_buildings_with_preds(aoi, run_name):\n",
    "    geo = get_unosat_geometry(aoi)\n",
    "    gdf_buildings = load_overture_buildings_aoi(aoi).set_index(\"building_id\")\n",
    "    preds = get_preds_geo(geo, run_name)\n",
    "    gdf_buildings_with_preds = add_preds_to_gdf(gdf_buildings, preds, verbose=0)\n",
    "\n",
    "    folder = PREDS_PATH / run_name / 'aoi_preds'\n",
    "    folder.mkdir(exist_ok=True, parents=True)\n",
    "    gdf_buildings_with_preds.to_file(folder / f'{aoi}_buildings_with_preds.geojson', driver='GeoJSON')\n",
    "    print(f\"Saved buildings with preds for aoi {aoi}.\")\n",
    "\n",
    "def create_all_aoi_buildings_with_preds(run_name):\n",
    "\n",
    "    with mp.Pool(4) as pool:\n",
    "        pool.starmap(create_aoi_buildings_with_preds, [(aoi, run_name) for aoi in get_all_aois()])\n",
    "\n",
    "def combine_all_unosat_buildings_with_preds(run_name):\n",
    "    gdf_ = None\n",
    "    for aoi in tqdm(get_all_aois()):\n",
    "        gdf = load_aoi_buildings_with_preds(aoi, run_name)\n",
    "        gdf = gdf[gdf['damage_5m'].isin([1,2])]\n",
    "        gdf['aoi'] = aoi\n",
    "        gdf_ = pd.concat([gdf_, gdf]) if gdf_ is not None else gdf\n",
    "    gdf_.to_file(PREDS_PATH / run_name / 'aoi_preds' / 'unosat_buildings_with_preds.geojson', driver='GeoJSON')\n",
    "\n",
    "def load_unosat_buildings_with_preds(run_name):\n",
    "    fp = PREDS_PATH / run_name / 'aoi_preds' / 'unosat_buildings_with_preds.geojson'\n",
    "    assert fp.exists(), f\"File {fp} does not exist.\"\n",
    "    return gpd.read_file(fp).set_index(['building_id', 'post_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_all_aoi_buildings_with_preds(run_name)\n",
    "# combine_all_unosat_buildings_with_preds(run_name)\n",
    "gdf = load_unosat_buildings_with_preds(run_name)\n",
    "gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(gdf, date, threshold, agg='weighted_mean', buffer=5):\n",
    "    gdf = gdf.loc[idx[:, date],:]\n",
    "    suffix = f'_{buffer}m' if buffer else ''\n",
    "\n",
    "    gdf = gdf[gdf['damage' + suffix].isin([1,2])]\n",
    "    gdf = gdf.groupby('unosat_id' + suffix).agg({\"weighted_mean\": \"mean\"})\n",
    "    tp = (gdf[agg]>=255*threshold).sum()\n",
    "    fn = (gdf[agg]<255*threshold).sum()\n",
    "    recall = tp/(tp+fn)\n",
    "    if date == '2021-02-24':\n",
    "        recall = 1-recall\n",
    "    # print(f\"TP: {tp} ({100*tp/(tp+fn):.2f}%), FN: {fn} ({100*fn/(tp+fn):.2f}%)\")\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for split in ['train', 'test']:\n",
    "    gdf_ = gdf[gdf.aoi.isin(aois_train if split=='train' else aois_test)]\n",
    "    d[split] = {}\n",
    "    for date in ['2021-02-24', '2022-02-24', '2023-02-24']:\n",
    "        d[split][date] = {}\n",
    "        for t in [0.5, 0.65, 0.75]:\n",
    "            recall = compute_metrics(gdf_, date, t, buffer=5)\n",
    "            d[split][date][t] = f'{recall:.2f}'\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
