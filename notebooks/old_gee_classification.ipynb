{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "\n",
    "from src.gee.utils import init_gee\n",
    "init_gee()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification in GEE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load precomputed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from src.gee.data.datasets import load_dataset, get_all_start_dates\n",
    "from src.gee.data.datasets import get_name_asset\n",
    "from src.gee.data.utils import get_base_asset_folder\n",
    "\n",
    "n_tiles=32\n",
    "extract_window=30\n",
    "split=\"train\"\n",
    "fold=None\n",
    "keep_damage=[1, 2]\n",
    "random_loc=0.1\n",
    "first_start_date=\"2020-06-01\"\n",
    "last_start_date=\"2022-06-01\"\n",
    "every_n_months = 1\n",
    "\n",
    "start_dates = get_all_start_dates(first_start_date, last_start_date, every_n_months=1)\n",
    "ds_train = None\n",
    "for i in range(len(start_dates)//4):\n",
    "    _start_dates = start_dates[i*4:(i+1)*4]\n",
    "    cfg_train = OmegaConf.create(\n",
    "        dict(\n",
    "            split=\"train\",\n",
    "            fold=None,\n",
    "            random_loc=random_loc,\n",
    "            keep_damage=keep_damage,\n",
    "            n_tiles=n_tiles,\n",
    "            extract_window=extract_window,\n",
    "            start_dates=_start_dates,\n",
    "            save_if_doesnt_exist=True,\n",
    "        )\n",
    "    )\n",
    "    _ds_train = load_dataset(**cfg_train)\n",
    "    ds_train = ds_train.merge(_ds_train) if ds_train is not None else _ds_train\n",
    "\n",
    "\n",
    "base_path = get_base_asset_folder(n_tiles, extract_window)\n",
    "asset_name = get_name_asset(split, fold, keep_damage, random_loc, start_dates)\n",
    "asset_path =base_path + f\"Final/{asset_name}\"\n",
    "\n",
    "task = ee.batch.Export.table.toAsset(\n",
    "    collection=ds_train,\n",
    "    description=asset_name,\n",
    "    assetId=asset_path,\n",
    ")\n",
    "#task.start()\n",
    "#print(f\"Task {asset_name} started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gee.data.datasets import load_dataset, get_all_start_dates\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "first_start_date = \"2020-06-01\"\n",
    "last_start_date = \"2022-05-01\"\n",
    "every_n_months = 1\n",
    "#start_dates = get_all_start_dates(first_start_date, last_start_date, every_n_months=every_n_months)\n",
    "\n",
    "# start_dates = [\"2020-06-01\", \"2020-10-01\", \"2021-06-01\", \"2021-10-01\"]\n",
    "start_dates = [\"2020-10-01\", \"2021-10-01\"]\n",
    "print(f\"Start dates: {start_dates}\")\n",
    "\n",
    "\n",
    "cfg_train = OmegaConf.create(\n",
    "    dict(\n",
    "        split=\"train\",\n",
    "        fold=None,\n",
    "        random_loc=0,\n",
    "        keep_damage=[1, 2],\n",
    "        n_tiles=32,\n",
    "        extract_window=30,\n",
    "        start_dates=start_dates,\n",
    "        save_if_doesnt_exist=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "cfg_test = OmegaConf.create(\n",
    "    dict(\n",
    "        split=\"test\",\n",
    "        fold=None,\n",
    "        random_loc=0,\n",
    "        keep_damage=[1, 2],\n",
    "        n_tiles=32,\n",
    "        extract_window=30,\n",
    "        start_dates=[\"2020-10-01\", \"2021-10-01\"],\n",
    "        save_if_doesnt_exist=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = load_dataset(**cfg_train)\n",
    "ds_test = load_dataset(**cfg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gee.classification.model import train_classifier\n",
    "\n",
    "cfg_model = OmegaConf.create(dict(\n",
    "    model_name='randomForest',\n",
    "    n_trees=50,\n",
    "    output_mode='CLASSIFICATION',\n",
    "))\n",
    "trained_clf = train_classifier(ds_train, **cfg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gee.classification.model import export_classifier\n",
    "from src.gee.data.datasets import get_name_asset\n",
    "from src.gee.data.utils import get_base_asset_folder\n",
    "\n",
    "model_name = get_name_asset(split='rf', fold=cfg_train.fold, keep_damage=cfg_train.keep_damage, random_perc=cfg_train.random_loc, start_dates=cfg_train.start_dates)\n",
    "base_folder = get_base_asset_folder(cfg_train.n_tiles, cfg_train.extract_window) + 'Models_trained/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_classifier(trained_clf, model_name, base_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while ee.data.getTaskList()[0]['state'] == 'RUNNING':\n",
    "    print('Running...')\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check metrics on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gee.classification.model import load_classifier\n",
    "from src.gee.classification.utils import compute_metrics\n",
    "\n",
    "#trained_clf = load_classifier(model_name, base_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ds_test.classify(trained_clf)\n",
    "compute_metrics(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_clf = trained_clf.setOutputMode('PROBABILITY')\n",
    "preds = ds_test.classify(trained_clf)\n",
    "compute_metrics(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ds_test.classify(trained_clf)\n",
    "compute_metrics(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_clf = trained_clf.setOutputMode('PROBABILITY')\n",
    "preds_proba = ds_test.classify(trained_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_predictions(preds):\n",
    "    unique_dates = preds.aggregate_array(\"startDate\").distinct()\n",
    "\n",
    "    def aggregate_date(date):\n",
    "        preds_date = preds.filter(ee.Filter.eq(\"startDate\", date))\n",
    "        unique_ids = preds_date.aggregate_array(\"unosat_id\").distinct()\n",
    "\n",
    "        def aggregate_id(id):\n",
    "            all_preds_date_id = preds_date.filter(ee.Filter.eq(\"unosat_id\", id))\n",
    "            geo = all_preds_date_id.first().geometry()\n",
    "            new_props = {\n",
    "                \"label\": ee.String(all_preds_date_id.first().get(\"label\")),\n",
    "                \"unosat_id\": ee.String(id),\n",
    "                \"start_date\": ee.String(date),\n",
    "                \"classification\": all_preds_date_id.aggregate_mean(\"classification\"),\n",
    "            }\n",
    "            new_feature = ee.Feature(ee.Geometry(geo), new_props)\n",
    "            return new_feature\n",
    "\n",
    "        _preds = ee.FeatureCollection(unique_ids.map(aggregate_id))\n",
    "        return _preds\n",
    "\n",
    "    return ee.FeatureCollection(unique_dates.map(aggregate_date)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_preds = aggregate_predictions(preds_proba)\n",
    "agg_preds = agg_preds.map(lambda f: f.set(\"classification_bin\", ee.Number(f.get(\"classification\")).gte(0.5)))\n",
    "compute_metrics(agg_preds, preds_name=\"classification_bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Large-scale (country-wide) predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.geometry import load_country_boundaries\n",
    "from src.utils.gee import shapely_to_gee\n",
    "ukraine_geo = load_country_boundaries('Ukraine')\n",
    "ukraine_geo_ee = shapely_to_gee(ukraine_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gee.data.unosat import get_unosat_geo\n",
    "from src.gee.data.collections import get_s1_collection\n",
    "from src.gee.classification.features_extractor import manual_stats_from_s1\n",
    "\n",
    "\n",
    "def inference(geo, start_date, trained_clf):\n",
    "    # Make sure output is probability\n",
    "    trained_clf = trained_clf.setOutputMode(\"PROBABILITY\")\n",
    "\n",
    "    s1 = get_s1_collection(geo, start=start_date)\n",
    "    orbits = (\n",
    "        s1.filterDate(start_date, ee.Date(start_date).advance(30, \"day\"))\n",
    "        .aggregate_array(\"relativeOrbitNumber_start\")\n",
    "        .distinct()\n",
    "    )\n",
    "\n",
    "    def inference_one_orbit(orbit):\n",
    "        s1_orbit = s1.filterMetadata(\"relativeOrbitNumber_start\", \"equals\", orbit).limit(32)\n",
    "        s1_orbit_stats = manual_stats_from_s1(s1_orbit)\n",
    "        preds = s1_orbit_stats.classify(trained_clf)\n",
    "        return preds\n",
    "\n",
    "    results = orbits.map(inference_one_orbit) # List of ee.Image\n",
    "    return ee.ImageCollection(results).mean()\n",
    "\n",
    "start_date = \"2021-10-01\"\n",
    "geo = get_unosat_geo(\"UKR1\")  # can be arbitrary geometry\n",
    "preds = inference(geo, start_date, trained_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.65\n",
    "vis_params = {\"min\": threshold, \"max\": 1, \"palette\": [\"yellow\", \"orange\", \"red\"]}\n",
    "\n",
    "def postprocessing(preds, threshold=0.5, smoothen=False, only_urban=True):\n",
    "\n",
    "    # Mask predictions below threshold\n",
    "    preds = preds.updateMask(preds.gte(threshold))\n",
    "\n",
    "    if smoothen:\n",
    "        # Smooth predictions\n",
    "        preds = preds.convolve(ee.Kernel.gaussian(radius=30, sigma=10, units='meters'))\n",
    "\n",
    "    #if only_urban:\n",
    "        # Mask predictions outside urban areas\n",
    "        #urban = ee.ImageCollection(\"JRC/GHSL/P2016/SMOD_POP_GLOBE_V1\").mosaic().select(\"smod_code\").eq(11)\n",
    "        #preds = preds.updateMask(urban)\n",
    "\n",
    "    return preds\n",
    "\n",
    "dataset = ee.Image('JRC/GHSL/P2016/BUILT_LDSMT_GLOBE_V1')\n",
    "builtUpMultitemporal = dataset.select('built')\n",
    "vis_params_urban = {\n",
    "  'min': 1.0,\n",
    "  'max': 6.0,\n",
    "  'palette': ['0c1d60', '000000', '448564', '70daa4', '83ffbf', 'ffffff'],\n",
    "}\n",
    "\n",
    "Map = geemap.Map()\n",
    "Map.addLayer(postprocessing(preds, threshold=threshold), vis_params, \"Predictions\")\n",
    "#Map.addLayer(builtUpMultitemporal, vis_params_urban, 'Built-Up Multitemporal')\n",
    "Map.centerObject(geo, 12)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start_date in get_all_start_dates(first_start_date, last_start_date, every_n_months=every_n_months):\n",
    "    preds = inference(geo, start_date, trained_clf)\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        preds,\n",
    "        description=f'Preds_Mariupol_{start_date}_2dates_random10.tif',\n",
    "        scale=10,\n",
    "        region=geo,\n",
    "        crs='EPSG:4326',\n",
    "        folder='TestPreds'\n",
    "    ).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Dummy classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gee.data.unosat import get_unosat_labels\n",
    "start = '2021-01-01'\n",
    "end = '2022-01-01'\n",
    "s1 = (\n",
    "    ee.ImageCollection(\"COPERNICUS/S1_GRD\")\n",
    "    .filter(ee.Filter.listContains(\"transmitterReceiverPolarisation\", \"VV\"))\n",
    "    .filter(ee.Filter.listContains(\"transmitterReceiverPolarisation\", \"VH\"))\n",
    "    .filter(ee.Filter.eq(\"instrumentMode\", \"IW\"))\n",
    "    .filter(ee.Filter.eq(\"platform_number\", \"A\"))\n",
    "    .filterDate(ee.Date(start), ee.Date(end))\n",
    ")\n",
    "points = ee.FeatureCollection('GOOGLE/EE/DEMOS/demo_landcover_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_sf = s1.filterBounds(points)\n",
    "s1_ukraine = s1.filterBounds(ukraine_geo_ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "Map.addLayer(s1_sf.mean(), {}, 'S1')\n",
    "Map.addLayer(s1_ukraine.mean(), {}, 'S1 Ukraine')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_reducers = (\n",
    "    ee.Reducer.mean()\n",
    "    .combine(reducer2=ee.Reducer.stdDev(), sharedInputs=True)\n",
    "    .combine(reducer2=ee.Reducer.median(), sharedInputs=True)\n",
    "    .combine(reducer2=ee.Reducer.max(), sharedInputs=True)\n",
    "    .combine(reducer2=ee.Reducer.min(), sharedInputs=True)\n",
    "    .combine(reducer2=ee.Reducer.skew(), sharedInputs=True)\n",
    "    .combine(reducer2=ee.Reducer.kurtosis(), sharedInputs=True)\n",
    "    .combine(reducer2=ee.Reducer.variance(), sharedInputs=True)\n",
    ")\n",
    "stats_sf = s1_sf.select(['VV','VH']).reduce(stats_reducers)\n",
    "stats_ukraine = s1_ukraine.select(['VV','VH']).reduce(stats_reducers)\n",
    "\n",
    "# get names bands\n",
    "bands = stats_sf.bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'landcover'\n",
    "training = stats_sf.sampleRegions(collection=points, properties=[label], scale=10, tileScale=2)\n",
    "#training.first().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds_train.select(bands + ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_trained = ee.Classifier.smileRandomForest(50).train(ds, 'label', bands)\n",
    "\n",
    "# Classify the image with the same bands used for training.\n",
    "preds = stats_ukraine.select(bands).classify(classifier_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "Map.addLayer(preds,\n",
    "             {'min': 0, 'max': 1, 'palette': ['orange', 'green']},\n",
    "             'classification')\n",
    "# Map.addLayer(s1.mean(), {'bands': ['VV' ,'VH', 'VV'], 'min': -10, 'max': 0}, 'image')\n",
    "# Map.addLayer(points, {}, 'points')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_inferred = preds.sampleRegions(collection=ds_test, properties=['label'], scale=10, tileScale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_inferred.first().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(ds_test_inferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = ds_test.select(bands + ['label']).classify(classifier_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(preds_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
